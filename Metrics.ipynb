{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "654b343c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from evaluate import load\n",
    "import mauve\n",
    "import nltk\n",
    "import numpy as np\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "from scipy.special import softmax\n",
    "import csv\n",
    "import urllib.request\n",
    "from nltk import word_tokenize, pos_tag\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9ca06f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The sun sets, casting a golden glow across the...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Flowers bloom, adding vibrant colors to the ga...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Laughter echoes through the air, filling heart...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gentle raindrops fall, refreshing the earth wi...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The moon shines brightly, illuminating the nig...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>High up in the mountains, where the air was cr...</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Under the starlit sky, a gentle breeze whisper...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>In the realm of dreams, where imagination know...</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>As the sun dipped below the horizon, painting ...</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>In the realm of infinite possibilities, where ...</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  length\n",
       "0    The sun sets, casting a golden glow across the...       7\n",
       "1    Flowers bloom, adding vibrant colors to the ga...       5\n",
       "2    Laughter echoes through the air, filling heart...      10\n",
       "3    Gentle raindrops fall, refreshing the earth wi...       8\n",
       "4    The moon shines brightly, illuminating the nig...       7\n",
       "..                                                 ...     ...\n",
       "139  High up in the mountains, where the air was cr...      51\n",
       "140  Under the starlit sky, a gentle breeze whisper...      61\n",
       "141  In the realm of dreams, where imagination know...      65\n",
       "142  As the sun dipped below the horizon, painting ...      70\n",
       "143  In the realm of infinite possibilities, where ...      73\n",
       "\n",
       "[144 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_generation = pd.read_csv('datasets/Generation_results/df_chat_len.csv')\n",
    "df_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fc977ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../230503_ucu_materials/data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c05ecde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    string = ''\n",
    "    for token in doc:\n",
    "        string += token.text\n",
    "        string += ' '\n",
    "    return string[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20d7f975",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_generation['text'] = df_generation['text'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de22a1f",
   "metadata": {},
   "source": [
    "# 1. Control metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "8a48c77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def part_of_speech(sentence):\n",
    "  pos = []\n",
    "  doc = nlp(sentence)\n",
    "  for token in doc:\n",
    "    pos.append(token.pos_)\n",
    "  return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9c76e7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sent(text):\n",
    "    new_text = []\n",
    " \n",
    " \n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "24ec0d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "task='sentiment'\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "\n",
    "labels=[]\n",
    "mapping_link = f\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/{task}/mapping.txt\"\n",
    "with urllib.request.urlopen(mapping_link) as f:\n",
    "    html = f.read().decode('utf-8').split(\"\\n\")\n",
    "    csvreader = csv.reader(html, delimiter='\\t')\n",
    "labels = [row[1] for row in csvreader if len(row) > 1]\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "model.save_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "af2438f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis(sentence):\n",
    "    sentence = preprocess_sent(sentence)\n",
    "    encoded_input = tokenizer(sentence, return_tensors='pt')\n",
    "    output = model(**encoded_input)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores) \n",
    "    return np.argmax(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "cdd0b4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tense_detect(sentence):\n",
    "  text = word_tokenize(sentence)\n",
    "  tagged = pos_tag(text)\n",
    "    \n",
    "  verb_tags = ['MD','MDF',\n",
    "              'BE','BEG','BEN','BED','BEDZ','BEZ','BEM','BER',\n",
    "              'DO','DOD','DOZ',\n",
    "              'HV','HVG','HVN','HVD','HVZ',\n",
    "              'VB','VBG','VBN','VBD','VBZ',\n",
    "              'SH',\n",
    "              'TO',\n",
    "              'JJ' # maybe?\n",
    "              ]\n",
    "    \n",
    "  verb_phrase = []\n",
    "  for item in tagged:\n",
    "    if item[1] in verb_tags:\n",
    "        verb_phrase.append(item)\n",
    "  if (verb_phrase == []):\n",
    "    return({'Not detected'})\n",
    "\n",
    "  grammar = r\"\"\"\n",
    "    future:                    {<MD><VB><VBN><VBG>}\n",
    "    future:                    {<MD><VB><VBG>}\n",
    "    future:                    {<MD><VB><VBN>}\n",
    "    past:                      {<VBD><VBN><VBG>}\n",
    "    present:                   {<VBP|VBZ><VBN><VBG>}\n",
    "    future:                    {<MD><VB>}\n",
    "    past:                      {<VBD><VBG>}\n",
    "    past:                      {<VBD><VBN>}\n",
    "    present:                   {<VBZ|VBP><VBG>}\n",
    "    present:                   {<VBZ|VBP><VBN>}\n",
    "    past:                      {<VBD>}\n",
    "    present:                   {<VBZ>|<VBP>}\n",
    "  \"\"\"\n",
    "\n",
    "  cp = nltk.RegexpParser(grammar)\n",
    "  result = cp.parse(verb_phrase)\n",
    "#  display(result)    \n",
    "                      \n",
    "  tenses_set = set()\n",
    "  for node in result:\n",
    "    if type(node) is nltk.tree.Tree:\n",
    "        tenses_set.add(node.label())\n",
    "  \n",
    "  return tenses_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "f99e5b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>pos</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tense</th>\n",
       "      <th>pos_check</th>\n",
       "      <th>sentiment_check</th>\n",
       "      <th>tense_check</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It â€™s useless .</td>\n",
       "      <td>PRON VERB ADJ PUNCT</td>\n",
       "      <td>negative</td>\n",
       "      <td>present</td>\n",
       "      <td>[PRON, VERB, ADJ, PUNCT]</td>\n",
       "      <td>0</td>\n",
       "      <td>{present}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>They had lost their entire expedition .</td>\n",
       "      <td>PRON AUX VERB PRON ADJ NOUN PUNCT</td>\n",
       "      <td>negative</td>\n",
       "      <td>past</td>\n",
       "      <td>[PRON, AUX, VERB, PRON, ADJ, NOUN, PUNCT]</td>\n",
       "      <td>0</td>\n",
       "      <td>{past}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It was painful .</td>\n",
       "      <td>PRON AUX ADJ PUNCT</td>\n",
       "      <td>negative</td>\n",
       "      <td>past</td>\n",
       "      <td>[PRON, AUX, ADJ, PUNCT]</td>\n",
       "      <td>0</td>\n",
       "      <td>{past}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It is painted .</td>\n",
       "      <td>PRON AUX VERB PUNCT</td>\n",
       "      <td>negative</td>\n",
       "      <td>present</td>\n",
       "      <td>[PRON, AUX, VERB, PUNCT]</td>\n",
       "      <td>1</td>\n",
       "      <td>{present}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Based on this will hurt business lending insti...</td>\n",
       "      <td>VERB ADP PRON AUX VERB NOUN VERB NOUN NOUN PUN...</td>\n",
       "      <td>negative</td>\n",
       "      <td>future</td>\n",
       "      <td>[VERB, ADP, PRON, AUX, VERB, NOUN, NOUN, NOUN,...</td>\n",
       "      <td>0</td>\n",
       "      <td>{future}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>He â€™s growing , out of growing to his max .</td>\n",
       "      <td>PRON AUX VERB PUNCT ADP ADP VERB ADP PRON NOUN...</td>\n",
       "      <td>positive</td>\n",
       "      <td>present</td>\n",
       "      <td>[PRON, AUX, VERB, PUNCT, ADP, ADP, VERB, ADP, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>{present}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>And despite California â€™s drought battling , m...</td>\n",
       "      <td>CCONJ SCONJ PROPN NOUN NOUN VERB PUNCT NOUN AD...</td>\n",
       "      <td>positive</td>\n",
       "      <td>past</td>\n",
       "      <td>[CCONJ, SCONJ, PROPN, NOUN, NOUN, VERB, PUNCT,...</td>\n",
       "      <td>1</td>\n",
       "      <td>{past}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>From the bench graphs above the reflected valu...</td>\n",
       "      <td>ADP DET NOUN VERB ADP DET VERB NOUN PUNCT ADJ ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>present</td>\n",
       "      <td>[ADP, DET, NOUN, NOUN, ADP, DET, VERB, NOUN, P...</td>\n",
       "      <td>2</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Research on self - driving cars shows to the p...</td>\n",
       "      <td>NOUN ADP NOUN PUNCT VERB NOUN VERB ADP DET NOU...</td>\n",
       "      <td>positive</td>\n",
       "      <td>present</td>\n",
       "      <td>[NOUN, ADP, NOUN, PUNCT, VERB, NOUN, VERB, ADP...</td>\n",
       "      <td>1</td>\n",
       "      <td>{present}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>This adds a healthy dinner rush reminiscent of...</td>\n",
       "      <td>PRON VERB DET ADJ NOUN NOUN ADJ ADP SYM NOUN A...</td>\n",
       "      <td>positive</td>\n",
       "      <td>present</td>\n",
       "      <td>[PRON, VERB, DET, ADJ, NOUN, NOUN, ADJ, ADP, S...</td>\n",
       "      <td>2</td>\n",
       "      <td>{present}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "0                                      It â€™s useless .   \n",
       "1              They had lost their entire expedition .   \n",
       "2                                     It was painful .   \n",
       "3                                      It is painted .   \n",
       "4    Based on this will hurt business lending insti...   \n",
       "..                                                 ...   \n",
       "995        He â€™s growing , out of growing to his max .   \n",
       "996  And despite California â€™s drought battling , m...   \n",
       "997  From the bench graphs above the reflected valu...   \n",
       "998  Research on self - driving cars shows to the p...   \n",
       "999  This adds a healthy dinner rush reminiscent of...   \n",
       "\n",
       "                                                   pos sentiment    tense  \\\n",
       "0                                  PRON VERB ADJ PUNCT  negative  present   \n",
       "1                    PRON AUX VERB PRON ADJ NOUN PUNCT  negative     past   \n",
       "2                                   PRON AUX ADJ PUNCT  negative     past   \n",
       "3                                  PRON AUX VERB PUNCT  negative  present   \n",
       "4    VERB ADP PRON AUX VERB NOUN VERB NOUN NOUN PUN...  negative   future   \n",
       "..                                                 ...       ...      ...   \n",
       "995  PRON AUX VERB PUNCT ADP ADP VERB ADP PRON NOUN...  positive  present   \n",
       "996  CCONJ SCONJ PROPN NOUN NOUN VERB PUNCT NOUN AD...  positive     past   \n",
       "997  ADP DET NOUN VERB ADP DET VERB NOUN PUNCT ADJ ...  positive  present   \n",
       "998  NOUN ADP NOUN PUNCT VERB NOUN VERB ADP DET NOU...  positive  present   \n",
       "999  PRON VERB DET ADJ NOUN NOUN ADJ ADP SYM NOUN A...  positive  present   \n",
       "\n",
       "                                             pos_check  sentiment_check  \\\n",
       "0                             [PRON, VERB, ADJ, PUNCT]                0   \n",
       "1            [PRON, AUX, VERB, PRON, ADJ, NOUN, PUNCT]                0   \n",
       "2                              [PRON, AUX, ADJ, PUNCT]                0   \n",
       "3                             [PRON, AUX, VERB, PUNCT]                1   \n",
       "4    [VERB, ADP, PRON, AUX, VERB, NOUN, NOUN, NOUN,...                0   \n",
       "..                                                 ...              ...   \n",
       "995  [PRON, AUX, VERB, PUNCT, ADP, ADP, VERB, ADP, ...                2   \n",
       "996  [CCONJ, SCONJ, PROPN, NOUN, NOUN, VERB, PUNCT,...                1   \n",
       "997  [ADP, DET, NOUN, NOUN, ADP, DET, VERB, NOUN, P...                2   \n",
       "998  [NOUN, ADP, NOUN, PUNCT, VERB, NOUN, VERB, ADP...                1   \n",
       "999  [PRON, VERB, DET, ADJ, NOUN, NOUN, ADJ, ADP, S...                2   \n",
       "\n",
       "    tense_check  \n",
       "0     {present}  \n",
       "1        {past}  \n",
       "2        {past}  \n",
       "3     {present}  \n",
       "4      {future}  \n",
       "..          ...  \n",
       "995   {present}  \n",
       "996      {past}  \n",
       "997          {}  \n",
       "998   {present}  \n",
       "999   {present}  \n",
       "\n",
       "[1000 rows x 7 columns]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_generation['pos_check'] = df_generation['text'].apply(part_of_speech)\n",
    "df_generation['sentiment_check'] = df_generation['text'].apply(sentiment_analysis)\n",
    "df_generation['tense_check'] = df_generation['text'].apply(tense_detect)\n",
    "df_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "31b57203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>pos</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tense</th>\n",
       "      <th>pos_check</th>\n",
       "      <th>sentiment_check</th>\n",
       "      <th>tense_check</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It â€™s useless .</td>\n",
       "      <td>[PRON, VERB, ADJ, PUNCT]</td>\n",
       "      <td>negative</td>\n",
       "      <td>present</td>\n",
       "      <td>[PRON, VERB, ADJ, PUNCT]</td>\n",
       "      <td>0</td>\n",
       "      <td>{present}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>They had lost their entire expedition .</td>\n",
       "      <td>[PRON, AUX, VERB, PRON, ADJ, NOUN, PUNCT]</td>\n",
       "      <td>negative</td>\n",
       "      <td>past</td>\n",
       "      <td>[PRON, AUX, VERB, PRON, ADJ, NOUN, PUNCT]</td>\n",
       "      <td>0</td>\n",
       "      <td>{past}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It was painful .</td>\n",
       "      <td>[PRON, AUX, ADJ, PUNCT]</td>\n",
       "      <td>negative</td>\n",
       "      <td>past</td>\n",
       "      <td>[PRON, AUX, ADJ, PUNCT]</td>\n",
       "      <td>0</td>\n",
       "      <td>{past}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It is painted .</td>\n",
       "      <td>[PRON, AUX, VERB, PUNCT]</td>\n",
       "      <td>negative</td>\n",
       "      <td>present</td>\n",
       "      <td>[PRON, AUX, VERB, PUNCT]</td>\n",
       "      <td>1</td>\n",
       "      <td>{present}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Based on this will hurt business lending insti...</td>\n",
       "      <td>[VERB, ADP, PRON, AUX, VERB, NOUN, VERB, NOUN,...</td>\n",
       "      <td>negative</td>\n",
       "      <td>future</td>\n",
       "      <td>[VERB, ADP, PRON, AUX, VERB, NOUN, NOUN, NOUN,...</td>\n",
       "      <td>0</td>\n",
       "      <td>{future}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>He â€™s growing , out of growing to his max .</td>\n",
       "      <td>[PRON, AUX, VERB, PUNCT, ADP, ADP, VERB, ADP, ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>present</td>\n",
       "      <td>[PRON, AUX, VERB, PUNCT, ADP, ADP, VERB, ADP, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>{present}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>And despite California â€™s drought battling , m...</td>\n",
       "      <td>[CCONJ, SCONJ, PROPN, NOUN, NOUN, VERB, PUNCT,...</td>\n",
       "      <td>positive</td>\n",
       "      <td>past</td>\n",
       "      <td>[CCONJ, SCONJ, PROPN, NOUN, NOUN, VERB, PUNCT,...</td>\n",
       "      <td>1</td>\n",
       "      <td>{past}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>From the bench graphs above the reflected valu...</td>\n",
       "      <td>[ADP, DET, NOUN, VERB, ADP, DET, VERB, NOUN, P...</td>\n",
       "      <td>positive</td>\n",
       "      <td>present</td>\n",
       "      <td>[ADP, DET, NOUN, NOUN, ADP, DET, VERB, NOUN, P...</td>\n",
       "      <td>2</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Research on self - driving cars shows to the p...</td>\n",
       "      <td>[NOUN, ADP, NOUN, PUNCT, VERB, NOUN, VERB, ADP...</td>\n",
       "      <td>positive</td>\n",
       "      <td>present</td>\n",
       "      <td>[NOUN, ADP, NOUN, PUNCT, VERB, NOUN, VERB, ADP...</td>\n",
       "      <td>1</td>\n",
       "      <td>{present}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>This adds a healthy dinner rush reminiscent of...</td>\n",
       "      <td>[PRON, VERB, DET, ADJ, NOUN, NOUN, ADJ, ADP, S...</td>\n",
       "      <td>positive</td>\n",
       "      <td>present</td>\n",
       "      <td>[PRON, VERB, DET, ADJ, NOUN, NOUN, ADJ, ADP, S...</td>\n",
       "      <td>2</td>\n",
       "      <td>{present}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "0                                      It â€™s useless .   \n",
       "1              They had lost their entire expedition .   \n",
       "2                                     It was painful .   \n",
       "3                                      It is painted .   \n",
       "4    Based on this will hurt business lending insti...   \n",
       "..                                                 ...   \n",
       "995        He â€™s growing , out of growing to his max .   \n",
       "996  And despite California â€™s drought battling , m...   \n",
       "997  From the bench graphs above the reflected valu...   \n",
       "998  Research on self - driving cars shows to the p...   \n",
       "999  This adds a healthy dinner rush reminiscent of...   \n",
       "\n",
       "                                                   pos sentiment    tense  \\\n",
       "0                             [PRON, VERB, ADJ, PUNCT]  negative  present   \n",
       "1            [PRON, AUX, VERB, PRON, ADJ, NOUN, PUNCT]  negative     past   \n",
       "2                              [PRON, AUX, ADJ, PUNCT]  negative     past   \n",
       "3                             [PRON, AUX, VERB, PUNCT]  negative  present   \n",
       "4    [VERB, ADP, PRON, AUX, VERB, NOUN, VERB, NOUN,...  negative   future   \n",
       "..                                                 ...       ...      ...   \n",
       "995  [PRON, AUX, VERB, PUNCT, ADP, ADP, VERB, ADP, ...  positive  present   \n",
       "996  [CCONJ, SCONJ, PROPN, NOUN, NOUN, VERB, PUNCT,...  positive     past   \n",
       "997  [ADP, DET, NOUN, VERB, ADP, DET, VERB, NOUN, P...  positive  present   \n",
       "998  [NOUN, ADP, NOUN, PUNCT, VERB, NOUN, VERB, ADP...  positive  present   \n",
       "999  [PRON, VERB, DET, ADJ, NOUN, NOUN, ADJ, ADP, S...  positive  present   \n",
       "\n",
       "                                             pos_check  sentiment_check  \\\n",
       "0                             [PRON, VERB, ADJ, PUNCT]                0   \n",
       "1            [PRON, AUX, VERB, PRON, ADJ, NOUN, PUNCT]                0   \n",
       "2                              [PRON, AUX, ADJ, PUNCT]                0   \n",
       "3                             [PRON, AUX, VERB, PUNCT]                1   \n",
       "4    [VERB, ADP, PRON, AUX, VERB, NOUN, NOUN, NOUN,...                0   \n",
       "..                                                 ...              ...   \n",
       "995  [PRON, AUX, VERB, PUNCT, ADP, ADP, VERB, ADP, ...                2   \n",
       "996  [CCONJ, SCONJ, PROPN, NOUN, NOUN, VERB, PUNCT,...                1   \n",
       "997  [ADP, DET, NOUN, NOUN, ADP, DET, VERB, NOUN, P...                2   \n",
       "998  [NOUN, ADP, NOUN, PUNCT, VERB, NOUN, VERB, ADP...                1   \n",
       "999  [PRON, VERB, DET, ADJ, NOUN, NOUN, ADJ, ADP, S...                2   \n",
       "\n",
       "    tense_check  \n",
       "0     {present}  \n",
       "1        {past}  \n",
       "2        {past}  \n",
       "3     {present}  \n",
       "4      {future}  \n",
       "..          ...  \n",
       "995   {present}  \n",
       "996      {past}  \n",
       "997          {}  \n",
       "998   {present}  \n",
       "999   {present}  \n",
       "\n",
       "[1000 rows x 7 columns]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_generation['pos'] = df_generation['pos'].apply(lambda row: row.split())\n",
    "df_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "2bbafe1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>pos</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tense</th>\n",
       "      <th>pos_check</th>\n",
       "      <th>sentiment_check</th>\n",
       "      <th>tense_check</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It â€™s useless .</td>\n",
       "      <td>[PRON, VERB, ADJ, PUNCT]</td>\n",
       "      <td>0</td>\n",
       "      <td>present</td>\n",
       "      <td>[PRON, VERB, ADJ, PUNCT]</td>\n",
       "      <td>0</td>\n",
       "      <td>{present}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>They had lost their entire expedition .</td>\n",
       "      <td>[PRON, AUX, VERB, PRON, ADJ, NOUN, PUNCT]</td>\n",
       "      <td>0</td>\n",
       "      <td>past</td>\n",
       "      <td>[PRON, AUX, VERB, PRON, ADJ, NOUN, PUNCT]</td>\n",
       "      <td>0</td>\n",
       "      <td>{past}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It was painful .</td>\n",
       "      <td>[PRON, AUX, ADJ, PUNCT]</td>\n",
       "      <td>0</td>\n",
       "      <td>past</td>\n",
       "      <td>[PRON, AUX, ADJ, PUNCT]</td>\n",
       "      <td>0</td>\n",
       "      <td>{past}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It is painted .</td>\n",
       "      <td>[PRON, AUX, VERB, PUNCT]</td>\n",
       "      <td>0</td>\n",
       "      <td>present</td>\n",
       "      <td>[PRON, AUX, VERB, PUNCT]</td>\n",
       "      <td>1</td>\n",
       "      <td>{present}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Based on this will hurt business lending insti...</td>\n",
       "      <td>[VERB, ADP, PRON, AUX, VERB, NOUN, VERB, NOUN,...</td>\n",
       "      <td>0</td>\n",
       "      <td>future</td>\n",
       "      <td>[VERB, ADP, PRON, AUX, VERB, NOUN, NOUN, NOUN,...</td>\n",
       "      <td>0</td>\n",
       "      <td>{future}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>He â€™s growing , out of growing to his max .</td>\n",
       "      <td>[PRON, AUX, VERB, PUNCT, ADP, ADP, VERB, ADP, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>present</td>\n",
       "      <td>[PRON, AUX, VERB, PUNCT, ADP, ADP, VERB, ADP, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>{present}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>And despite California â€™s drought battling , m...</td>\n",
       "      <td>[CCONJ, SCONJ, PROPN, NOUN, NOUN, VERB, PUNCT,...</td>\n",
       "      <td>2</td>\n",
       "      <td>past</td>\n",
       "      <td>[CCONJ, SCONJ, PROPN, NOUN, NOUN, VERB, PUNCT,...</td>\n",
       "      <td>1</td>\n",
       "      <td>{past}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>From the bench graphs above the reflected valu...</td>\n",
       "      <td>[ADP, DET, NOUN, VERB, ADP, DET, VERB, NOUN, P...</td>\n",
       "      <td>2</td>\n",
       "      <td>present</td>\n",
       "      <td>[ADP, DET, NOUN, NOUN, ADP, DET, VERB, NOUN, P...</td>\n",
       "      <td>2</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Research on self - driving cars shows to the p...</td>\n",
       "      <td>[NOUN, ADP, NOUN, PUNCT, VERB, NOUN, VERB, ADP...</td>\n",
       "      <td>2</td>\n",
       "      <td>present</td>\n",
       "      <td>[NOUN, ADP, NOUN, PUNCT, VERB, NOUN, VERB, ADP...</td>\n",
       "      <td>1</td>\n",
       "      <td>{present}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>This adds a healthy dinner rush reminiscent of...</td>\n",
       "      <td>[PRON, VERB, DET, ADJ, NOUN, NOUN, ADJ, ADP, S...</td>\n",
       "      <td>2</td>\n",
       "      <td>present</td>\n",
       "      <td>[PRON, VERB, DET, ADJ, NOUN, NOUN, ADJ, ADP, S...</td>\n",
       "      <td>2</td>\n",
       "      <td>{present}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "0                                      It â€™s useless .   \n",
       "1              They had lost their entire expedition .   \n",
       "2                                     It was painful .   \n",
       "3                                      It is painted .   \n",
       "4    Based on this will hurt business lending insti...   \n",
       "..                                                 ...   \n",
       "995        He â€™s growing , out of growing to his max .   \n",
       "996  And despite California â€™s drought battling , m...   \n",
       "997  From the bench graphs above the reflected valu...   \n",
       "998  Research on self - driving cars shows to the p...   \n",
       "999  This adds a healthy dinner rush reminiscent of...   \n",
       "\n",
       "                                                   pos  sentiment    tense  \\\n",
       "0                             [PRON, VERB, ADJ, PUNCT]          0  present   \n",
       "1            [PRON, AUX, VERB, PRON, ADJ, NOUN, PUNCT]          0     past   \n",
       "2                              [PRON, AUX, ADJ, PUNCT]          0     past   \n",
       "3                             [PRON, AUX, VERB, PUNCT]          0  present   \n",
       "4    [VERB, ADP, PRON, AUX, VERB, NOUN, VERB, NOUN,...          0   future   \n",
       "..                                                 ...        ...      ...   \n",
       "995  [PRON, AUX, VERB, PUNCT, ADP, ADP, VERB, ADP, ...          2  present   \n",
       "996  [CCONJ, SCONJ, PROPN, NOUN, NOUN, VERB, PUNCT,...          2     past   \n",
       "997  [ADP, DET, NOUN, VERB, ADP, DET, VERB, NOUN, P...          2  present   \n",
       "998  [NOUN, ADP, NOUN, PUNCT, VERB, NOUN, VERB, ADP...          2  present   \n",
       "999  [PRON, VERB, DET, ADJ, NOUN, NOUN, ADJ, ADP, S...          2  present   \n",
       "\n",
       "                                             pos_check  sentiment_check  \\\n",
       "0                             [PRON, VERB, ADJ, PUNCT]                0   \n",
       "1            [PRON, AUX, VERB, PRON, ADJ, NOUN, PUNCT]                0   \n",
       "2                              [PRON, AUX, ADJ, PUNCT]                0   \n",
       "3                             [PRON, AUX, VERB, PUNCT]                1   \n",
       "4    [VERB, ADP, PRON, AUX, VERB, NOUN, NOUN, NOUN,...                0   \n",
       "..                                                 ...              ...   \n",
       "995  [PRON, AUX, VERB, PUNCT, ADP, ADP, VERB, ADP, ...                2   \n",
       "996  [CCONJ, SCONJ, PROPN, NOUN, NOUN, VERB, PUNCT,...                1   \n",
       "997  [ADP, DET, NOUN, NOUN, ADP, DET, VERB, NOUN, P...                2   \n",
       "998  [NOUN, ADP, NOUN, PUNCT, VERB, NOUN, VERB, ADP...                1   \n",
       "999  [PRON, VERB, DET, ADJ, NOUN, NOUN, ADJ, ADP, S...                2   \n",
       "\n",
       "    tense_check  \n",
       "0     {present}  \n",
       "1        {past}  \n",
       "2        {past}  \n",
       "3     {present}  \n",
       "4      {future}  \n",
       "..          ...  \n",
       "995   {present}  \n",
       "996      {past}  \n",
       "997          {}  \n",
       "998   {present}  \n",
       "999   {present}  \n",
       "\n",
       "[1000 rows x 7 columns]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_generation['sentiment'] = df_generation['sentiment'].replace('positive', 2)\n",
    "df_generation['sentiment'] = df_generation['sentiment'].replace('neutral', 1)\n",
    "df_generation['sentiment'] = df_generation['sentiment'].replace('negative', 0)\n",
    "df_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "6ca1a4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_generation['lentense'] = df_generation['tense_check'].apply(len)\n",
    "df_generation.loc[df_generation['tense_check'] == {'Not detected'}, 'lentense'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b3c819d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def length_exact(df):\n",
    "    expected_length_indexes = df.apply(lambda row: (len(row['text'].split(' ')) == row['length']), axis=1)\n",
    "    return sum(expected_length_indexes)/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3ddcfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def length_approximate(df):\n",
    "    expected_length_indexes = df.apply(lambda row: ((len(row['text'].split(' ')) <= row['length'] + 3) & (len(row['text'].split(' ')) >= row['length'] - 3)), axis=1)\n",
    "    return sum(expected_length_indexes)/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "16740685",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_exact(df):\n",
    "    expected_pos_indexes = df.apply(lambda row: (row['pos'] == row['pos_check']), axis=1)\n",
    "    return sum(expected_pos_indexes)/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "158e5194",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_unique_without_order(df):\n",
    "    pos_unigrams_match = df.apply(lambda row: (len(set(row['pos']) & set(row['pos_check']))/len(set(row['pos']))), axis=1)\n",
    "    return pos_unigrams_match.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "5f8ddea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigrams(l1, l2):\n",
    "    number_bigrams = 0\n",
    "    bigrams_l2 =[]\n",
    "    for j in range(len(l2) - 1):\n",
    "        bigrams_l2.append([l2[j], l2[j + 1]])\n",
    "    for i in range(len(l1) - 1):\n",
    "        sublist = [l1[i], l1[i + 1]]\n",
    "        if sublist in bigrams_l2: number_bigrams += 1\n",
    "    return number_bigrams/(len(l1) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "e089042d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trigrams(l1, l2):\n",
    "    number_trigrams = 0\n",
    "    trigrams_l2 =[]\n",
    "    for j in range(len(l2) - 2):\n",
    "        trigrams_l2.append([l2[j], l2[j + 1], l2[j + 2]])\n",
    "    for i in range(len(l1) - 2):\n",
    "        sublist = [l1[i], l1[i + 1], l1[i + 2]]\n",
    "        if sublist in trigrams_l2: number_trigrams += 1\n",
    "    return number_trigrams/(len(l1) - 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "d0232152",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_bigrams(df):\n",
    "    pos_bigrams_match = df.apply(lambda row: bigrams(row['pos'], row['pos_check']), axis=1)\n",
    "    return pos_bigrams_match.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "73c3538d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_trigrams(df):\n",
    "    pos_trigrams_match = df.apply(lambda row: trigrams(row['pos'], row['pos_check']), axis=1)\n",
    "    return pos_trigrams_match.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc62a5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def needleman_wunsch(seq1, seq2, match_score=1, mismatch_score=-1, gap_penalty=-1):\n",
    "    \"\"\"\n",
    "    Very simple aligning algorithm.\n",
    "    \"\"\"\n",
    "\n",
    "    m, n = len(seq1), len(seq2)\n",
    "    score_matrix = np.zeros((m + 1, n + 1), dtype=int)\n",
    "\n",
    "    for i in range(m + 1):\n",
    "        score_matrix[i, 0] = i * gap_penalty\n",
    "    for j in range(n + 1):\n",
    "        score_matrix[0, j] = j * gap_penalty\n",
    "\n",
    "    for i in range(1, m + 1):\n",
    "        for j in range(1, n + 1):\n",
    "            match = score_matrix[i - 1, j - 1] + (match_score if seq1[i - 1] == seq2[j - 1] else mismatch_score)\n",
    "            delete = score_matrix[i - 1, j] + gap_penalty\n",
    "            insert = score_matrix[i, j - 1] + gap_penalty\n",
    "            score_matrix[i, j] = max(match, delete, insert)\n",
    "\n",
    "    aligned_seq1 = []\n",
    "    aligned_seq2 = []\n",
    "    i, j = m, n\n",
    "\n",
    "    while i > 0 or j > 0:\n",
    "        if i > 0 and j > 0 and score_matrix[i, j] == score_matrix[i - 1, j - 1] + (match_score if seq1[i - 1] == seq2[j - 1] else mismatch_score):\n",
    "            aligned_seq1.append(seq1[i - 1])\n",
    "            aligned_seq2.append(seq2[j - 1])\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "        elif i > 0 and score_matrix[i, j] == score_matrix[i - 1, j] + gap_penalty:\n",
    "            aligned_seq1.append(seq1[i - 1])\n",
    "            aligned_seq2.append('-')\n",
    "            i -= 1\n",
    "        else:\n",
    "            aligned_seq1.append('-')\n",
    "            aligned_seq2.append(seq2[j - 1])\n",
    "            j -= 1\n",
    "\n",
    "    aligned_seq1 = list(reversed(aligned_seq1))\n",
    "    aligned_seq2 = list(reversed(aligned_seq2))\n",
    "\n",
    "    return aligned_seq1, aligned_seq2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6ee94ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_alignment(df):\n",
    "    matches = []\n",
    "    for i in range(len(df)):\n",
    "        aligned_input, aligned_pred = needleman_wunsch(df['pos'][i], df['pos_check'][i])\n",
    "        matches += [g == p for g,p in zip(aligned_input, aligned_pred)]\n",
    "    return np.mean(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fde80de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PRON', '-', 'VERB', 'ADJ', 'PUNCT']\n",
      "['PRON', 'AUX', 'VERB', '-', 'PUNCT']\n"
     ]
    }
   ],
   "source": [
    "sequence_1 = ['PRON', 'VERB', 'ADJ', 'PUNCT']\n",
    "sequence_2 = ['PRON', 'AUX', 'VERB', 'PUNCT']\n",
    "print(needleman_wunsch(sequence_1, sequence_2)[0])\n",
    "print(needleman_wunsch(sequence_1, sequence_2)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e6678c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aligned_input, aligned_pred = needleman_wunsch(sequence_1, sequence_2)\n",
    "np.mean([g == p for g,p in zip(aligned_input, aligned_pred)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "568e240c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_exact(df):\n",
    "    expected_sentiment_indexes = df.apply(lambda row: (row['sentiment'] == row['sentiment_check']), axis=1)\n",
    "    return sum(expected_sentiment_indexes)/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "06898bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_approximate(df):\n",
    "    expected_sentiment_indexes = df.apply(lambda row: (abs(row['sentiment'] - row['sentiment_check']) <= 1), axis=1)\n",
    "    return sum(expected_sentiment_indexes)/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "93181023",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tense_exact(df):\n",
    "    expected_tense_indexes = df.apply(lambda row: (row['tense'] in row['tense_check']), axis=1)\n",
    "    return sum(expected_tense_indexes)/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "02ed383a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09722222222222222"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_exact(df_generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a99a5114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5833333333333334"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_approximate(df_generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8aab7b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_generation[(df_generation['length'] >= 71) & (df_generation['length'] <= 80)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f418d19e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_exact(df_generation[(df_generation['length'] >= 71) & (df_generation['length'] <= 80)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d7a90244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_approximate(df_generation[(df_generation['length'] >= 71) & (df_generation['length'] <= 80)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "a66dfe05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.409"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_exact(df_generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "c06a4d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9739657814407808"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_unique_without_order(df_generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "f57e39ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9208244288884342"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_bigrams(df_generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "ee270e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8624456179935579"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_trigrams(df_generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "de38ae41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9263997033741194"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_alignment(df_generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "a69740c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>pos</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tense</th>\n",
       "      <th>pos_check</th>\n",
       "      <th>sentiment_check</th>\n",
       "      <th>tense_check</th>\n",
       "      <th>lentense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>You can also enable Harmony to train your Imam...</td>\n",
       "      <td>[PRON, AUX, ADV, VERB, PROPN, PART, VERB, PRON...</td>\n",
       "      <td>2</td>\n",
       "      <td>future</td>\n",
       "      <td>[PRON, AUX, ADV, VERB, PROPN, PART, VERB, PRON...</td>\n",
       "      <td>1</td>\n",
       "      <td>{future}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>But on the flight of the trade - off was a suc...</td>\n",
       "      <td>[CCONJ, ADP, DET, NOUN, ADP, DET, NOUN, PUNCT,...</td>\n",
       "      <td>2</td>\n",
       "      <td>past</td>\n",
       "      <td>[CCONJ, ADP, DET, NOUN, ADP, DET, NOUN, PUNCT,...</td>\n",
       "      <td>2</td>\n",
       "      <td>{past}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>When the Eastern States wins and then loses mo...</td>\n",
       "      <td>[SCONJ, DET, PROPN, PROPN, VERB, CCONJ, ADV, V...</td>\n",
       "      <td>2</td>\n",
       "      <td>present</td>\n",
       "      <td>[SCONJ, DET, PROPN, PROPN, VERB, CCONJ, ADV, V...</td>\n",
       "      <td>1</td>\n",
       "      <td>{present}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>At 8:30 a.m. the UFC Fight Night begins previe...</td>\n",
       "      <td>[ADP, NUM, DET, PROPN, PROPN, PROPN, VERB, VER...</td>\n",
       "      <td>2</td>\n",
       "      <td>future</td>\n",
       "      <td>[ADP, NUM, NOUN, DET, PROPN, PROPN, PROPN, VER...</td>\n",
       "      <td>1</td>\n",
       "      <td>{present}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>That 'd be slightly more fun .</td>\n",
       "      <td>[PRON, AUX, PART, ADV, ADJ, NOUN, PUNCT]</td>\n",
       "      <td>2</td>\n",
       "      <td>future</td>\n",
       "      <td>[PRON, AUX, AUX, ADV, ADJ, NOUN, PUNCT]</td>\n",
       "      <td>2</td>\n",
       "      <td>{future}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>He â€™s growing , out of growing to his max .</td>\n",
       "      <td>[PRON, AUX, VERB, PUNCT, ADP, ADP, VERB, ADP, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>present</td>\n",
       "      <td>[PRON, AUX, VERB, PUNCT, ADP, ADP, VERB, ADP, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>{present}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>And despite California â€™s drought battling , m...</td>\n",
       "      <td>[CCONJ, SCONJ, PROPN, NOUN, NOUN, VERB, PUNCT,...</td>\n",
       "      <td>2</td>\n",
       "      <td>past</td>\n",
       "      <td>[CCONJ, SCONJ, PROPN, NOUN, NOUN, VERB, PUNCT,...</td>\n",
       "      <td>1</td>\n",
       "      <td>{past}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>From the bench graphs above the reflected valu...</td>\n",
       "      <td>[ADP, DET, NOUN, VERB, ADP, DET, VERB, NOUN, P...</td>\n",
       "      <td>2</td>\n",
       "      <td>present</td>\n",
       "      <td>[ADP, DET, NOUN, NOUN, ADP, DET, VERB, NOUN, P...</td>\n",
       "      <td>2</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Research on self - driving cars shows to the p...</td>\n",
       "      <td>[NOUN, ADP, NOUN, PUNCT, VERB, NOUN, VERB, ADP...</td>\n",
       "      <td>2</td>\n",
       "      <td>present</td>\n",
       "      <td>[NOUN, ADP, NOUN, PUNCT, VERB, NOUN, VERB, ADP...</td>\n",
       "      <td>1</td>\n",
       "      <td>{present}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>This adds a healthy dinner rush reminiscent of...</td>\n",
       "      <td>[PRON, VERB, DET, ADJ, NOUN, NOUN, ADJ, ADP, S...</td>\n",
       "      <td>2</td>\n",
       "      <td>present</td>\n",
       "      <td>[PRON, VERB, DET, ADJ, NOUN, NOUN, ADJ, ADP, S...</td>\n",
       "      <td>2</td>\n",
       "      <td>{present}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>333 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "667  You can also enable Harmony to train your Imam...   \n",
       "668  But on the flight of the trade - off was a suc...   \n",
       "669  When the Eastern States wins and then loses mo...   \n",
       "670  At 8:30 a.m. the UFC Fight Night begins previe...   \n",
       "671                     That 'd be slightly more fun .   \n",
       "..                                                 ...   \n",
       "995        He â€™s growing , out of growing to his max .   \n",
       "996  And despite California â€™s drought battling , m...   \n",
       "997  From the bench graphs above the reflected valu...   \n",
       "998  Research on self - driving cars shows to the p...   \n",
       "999  This adds a healthy dinner rush reminiscent of...   \n",
       "\n",
       "                                                   pos  sentiment    tense  \\\n",
       "667  [PRON, AUX, ADV, VERB, PROPN, PART, VERB, PRON...          2   future   \n",
       "668  [CCONJ, ADP, DET, NOUN, ADP, DET, NOUN, PUNCT,...          2     past   \n",
       "669  [SCONJ, DET, PROPN, PROPN, VERB, CCONJ, ADV, V...          2  present   \n",
       "670  [ADP, NUM, DET, PROPN, PROPN, PROPN, VERB, VER...          2   future   \n",
       "671           [PRON, AUX, PART, ADV, ADJ, NOUN, PUNCT]          2   future   \n",
       "..                                                 ...        ...      ...   \n",
       "995  [PRON, AUX, VERB, PUNCT, ADP, ADP, VERB, ADP, ...          2  present   \n",
       "996  [CCONJ, SCONJ, PROPN, NOUN, NOUN, VERB, PUNCT,...          2     past   \n",
       "997  [ADP, DET, NOUN, VERB, ADP, DET, VERB, NOUN, P...          2  present   \n",
       "998  [NOUN, ADP, NOUN, PUNCT, VERB, NOUN, VERB, ADP...          2  present   \n",
       "999  [PRON, VERB, DET, ADJ, NOUN, NOUN, ADJ, ADP, S...          2  present   \n",
       "\n",
       "                                             pos_check  sentiment_check  \\\n",
       "667  [PRON, AUX, ADV, VERB, PROPN, PART, VERB, PRON...                1   \n",
       "668  [CCONJ, ADP, DET, NOUN, ADP, DET, NOUN, PUNCT,...                2   \n",
       "669  [SCONJ, DET, PROPN, PROPN, VERB, CCONJ, ADV, V...                1   \n",
       "670  [ADP, NUM, NOUN, DET, PROPN, PROPN, PROPN, VER...                1   \n",
       "671            [PRON, AUX, AUX, ADV, ADJ, NOUN, PUNCT]                2   \n",
       "..                                                 ...              ...   \n",
       "995  [PRON, AUX, VERB, PUNCT, ADP, ADP, VERB, ADP, ...                2   \n",
       "996  [CCONJ, SCONJ, PROPN, NOUN, NOUN, VERB, PUNCT,...                1   \n",
       "997  [ADP, DET, NOUN, NOUN, ADP, DET, VERB, NOUN, P...                2   \n",
       "998  [NOUN, ADP, NOUN, PUNCT, VERB, NOUN, VERB, ADP...                1   \n",
       "999  [PRON, VERB, DET, ADJ, NOUN, NOUN, ADJ, ADP, S...                2   \n",
       "\n",
       "    tense_check  lentense  \n",
       "667    {future}         1  \n",
       "668      {past}         1  \n",
       "669   {present}         1  \n",
       "670   {present}         1  \n",
       "671    {future}         1  \n",
       "..          ...       ...  \n",
       "995   {present}         1  \n",
       "996      {past}         1  \n",
       "997          {}         0  \n",
       "998   {present}         1  \n",
       "999   {present}         1  \n",
       "\n",
       "[333 rows x 8 columns]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_generation[df_generation['sentiment'] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "8ea61432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47147147147147145"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_exact(df_generation[df_generation['sentiment'] == 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "436a9c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9459459459459459"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_approximate(df_generation[df_generation['sentiment'] == 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "8015f0ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>pos</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tense</th>\n",
       "      <th>pos_check</th>\n",
       "      <th>sentiment_check</th>\n",
       "      <th>tense_check</th>\n",
       "      <th>lentense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Based on this will hurt business lending insti...</td>\n",
       "      <td>[VERB, ADP, PRON, AUX, VERB, NOUN, VERB, NOUN,...</td>\n",
       "      <td>0</td>\n",
       "      <td>future</td>\n",
       "      <td>[VERB, ADP, PRON, AUX, VERB, NOUN, NOUN, NOUN,...</td>\n",
       "      <td>0</td>\n",
       "      <td>{future}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>You must hate that .</td>\n",
       "      <td>[PRON, AUX, VERB, PRON, PUNCT]</td>\n",
       "      <td>0</td>\n",
       "      <td>future</td>\n",
       "      <td>[PRON, AUX, VERB, PRON, PUNCT]</td>\n",
       "      <td>0</td>\n",
       "      <td>{future}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>They will refuse the plan to give up .</td>\n",
       "      <td>[PRON, AUX, VERB, DET, NOUN, PART, VERB, ADP, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>future</td>\n",
       "      <td>[PRON, AUX, VERB, DET, NOUN, PART, VERB, ADP, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>{future}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>You will now miss .</td>\n",
       "      <td>[PRON, AUX, ADV, ADJ, PUNCT]</td>\n",
       "      <td>0</td>\n",
       "      <td>future</td>\n",
       "      <td>[PRON, AUX, ADV, VERB, PUNCT]</td>\n",
       "      <td>1</td>\n",
       "      <td>{future}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>It â€™s pretty boring .</td>\n",
       "      <td>[PRON, VERB, ADV, ADJ, PUNCT]</td>\n",
       "      <td>0</td>\n",
       "      <td>future</td>\n",
       "      <td>[PRON, VERB, ADV, ADJ, PUNCT]</td>\n",
       "      <td>0</td>\n",
       "      <td>{present}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>But I ca nâ€™t wait to be a singing partner to â€œ...</td>\n",
       "      <td>[CCONJ, PRON, AUX, PROPN, VERB, PART, AUX, DET...</td>\n",
       "      <td>2</td>\n",
       "      <td>future</td>\n",
       "      <td>[CCONJ, PRON, AUX, NOUN, VERB, PART, AUX, DET,...</td>\n",
       "      <td>2</td>\n",
       "      <td>{future}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>For the first time and in the US , for revenue...</td>\n",
       "      <td>[ADP, DET, ADJ, NOUN, CCONJ, ADP, DET, PROPN, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>future</td>\n",
       "      <td>[ADP, DET, ADJ, NOUN, CCONJ, ADP, DET, PROPN, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>{present}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>We are being funded right this way with whatev...</td>\n",
       "      <td>[PRON, AUX, AUX, VERB, ADV, DET, NOUN, ADP, PR...</td>\n",
       "      <td>2</td>\n",
       "      <td>future</td>\n",
       "      <td>[PRON, AUX, AUX, VERB, ADV, DET, NOUN, ADP, PR...</td>\n",
       "      <td>1</td>\n",
       "      <td>{future}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>In his role , President Obama won the Democrat...</td>\n",
       "      <td>[ADP, PRON, NOUN, PUNCT, PROPN, PROPN, VERB, D...</td>\n",
       "      <td>2</td>\n",
       "      <td>future</td>\n",
       "      <td>[ADP, PRON, NOUN, PUNCT, PROPN, PROPN, VERB, D...</td>\n",
       "      <td>2</td>\n",
       "      <td>{past}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>You can just play any game , and you can just ...</td>\n",
       "      <td>[PRON, AUX, ADV, VERB, DET, NOUN, PUNCT, CCONJ...</td>\n",
       "      <td>2</td>\n",
       "      <td>future</td>\n",
       "      <td>[PRON, AUX, ADV, VERB, DET, NOUN, PUNCT, CCONJ...</td>\n",
       "      <td>1</td>\n",
       "      <td>{future}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>235 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "4    Based on this will hurt business lending insti...   \n",
       "5                                 You must hate that .   \n",
       "6               They will refuse the plan to give up .   \n",
       "8                                  You will now miss .   \n",
       "9                                It â€™s pretty boring .   \n",
       "..                                                 ...   \n",
       "975  But I ca nâ€™t wait to be a singing partner to â€œ...   \n",
       "982  For the first time and in the US , for revenue...   \n",
       "985  We are being funded right this way with whatev...   \n",
       "986  In his role , President Obama won the Democrat...   \n",
       "992  You can just play any game , and you can just ...   \n",
       "\n",
       "                                                   pos  sentiment   tense  \\\n",
       "4    [VERB, ADP, PRON, AUX, VERB, NOUN, VERB, NOUN,...          0  future   \n",
       "5                       [PRON, AUX, VERB, PRON, PUNCT]          0  future   \n",
       "6    [PRON, AUX, VERB, DET, NOUN, PART, VERB, ADP, ...          0  future   \n",
       "8                         [PRON, AUX, ADV, ADJ, PUNCT]          0  future   \n",
       "9                        [PRON, VERB, ADV, ADJ, PUNCT]          0  future   \n",
       "..                                                 ...        ...     ...   \n",
       "975  [CCONJ, PRON, AUX, PROPN, VERB, PART, AUX, DET...          2  future   \n",
       "982  [ADP, DET, ADJ, NOUN, CCONJ, ADP, DET, PROPN, ...          2  future   \n",
       "985  [PRON, AUX, AUX, VERB, ADV, DET, NOUN, ADP, PR...          2  future   \n",
       "986  [ADP, PRON, NOUN, PUNCT, PROPN, PROPN, VERB, D...          2  future   \n",
       "992  [PRON, AUX, ADV, VERB, DET, NOUN, PUNCT, CCONJ...          2  future   \n",
       "\n",
       "                                             pos_check  sentiment_check  \\\n",
       "4    [VERB, ADP, PRON, AUX, VERB, NOUN, NOUN, NOUN,...                0   \n",
       "5                       [PRON, AUX, VERB, PRON, PUNCT]                0   \n",
       "6    [PRON, AUX, VERB, DET, NOUN, PART, VERB, ADP, ...                0   \n",
       "8                        [PRON, AUX, ADV, VERB, PUNCT]                1   \n",
       "9                        [PRON, VERB, ADV, ADJ, PUNCT]                0   \n",
       "..                                                 ...              ...   \n",
       "975  [CCONJ, PRON, AUX, NOUN, VERB, PART, AUX, DET,...                2   \n",
       "982  [ADP, DET, ADJ, NOUN, CCONJ, ADP, DET, PROPN, ...                1   \n",
       "985  [PRON, AUX, AUX, VERB, ADV, DET, NOUN, ADP, PR...                1   \n",
       "986  [ADP, PRON, NOUN, PUNCT, PROPN, PROPN, VERB, D...                2   \n",
       "992  [PRON, AUX, ADV, VERB, DET, NOUN, PUNCT, CCONJ...                1   \n",
       "\n",
       "    tense_check  lentense  \n",
       "4      {future}         1  \n",
       "5      {future}         1  \n",
       "6      {future}         1  \n",
       "8      {future}         1  \n",
       "9     {present}         1  \n",
       "..          ...       ...  \n",
       "975    {future}         1  \n",
       "982   {present}         1  \n",
       "985    {future}         1  \n",
       "986      {past}         1  \n",
       "992    {future}         1  \n",
       "\n",
       "[235 rows x 8 columns]"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_generation[(df_generation['lentense'] > 0) & (df_generation['tense'] == 'future')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "8dabaaed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7914893617021277"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tense_exact(df_generation[(df_generation['lentense'] > 0) & (df_generation['tense'] == 'future')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960508da",
   "metadata": {},
   "source": [
    "# 2. Fluency metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a64d1f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexity = load(\"perplexity\", module_type=\"metric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2dbc6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perpl(df):\n",
    "    perplexities = perplexity.compute(predictions=df['text'].values.tolist(), model_id='gpt2', device='cpu')\n",
    "    df['perplexity'] = perplexities['perplexities']\n",
    "    return perplexities['mean_perplexity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0656cf4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7b37ed670d546d49ae63250ec42a35a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "78.09138695398967"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perpl(df_generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e40d1a09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "      <th>perplexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The sun sets , casting a golden glow across th...</td>\n",
       "      <td>7</td>\n",
       "      <td>123.059952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Flowers bloom , adding vibrant colors to the g...</td>\n",
       "      <td>5</td>\n",
       "      <td>137.638031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Laughter echoes through the air , filling hear...</td>\n",
       "      <td>10</td>\n",
       "      <td>125.766365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gentle raindrops fall , refreshing the earth w...</td>\n",
       "      <td>8</td>\n",
       "      <td>174.783737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The moon shines brightly , illuminating the ni...</td>\n",
       "      <td>7</td>\n",
       "      <td>42.624065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>High up in the mountains , where the air was c...</td>\n",
       "      <td>51</td>\n",
       "      <td>31.506687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Under the starlit sky , a gentle breeze whispe...</td>\n",
       "      <td>61</td>\n",
       "      <td>47.097542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>In the realm of dreams , where imagination kno...</td>\n",
       "      <td>65</td>\n",
       "      <td>31.966364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>As the sun dipped below the horizon , painting...</td>\n",
       "      <td>70</td>\n",
       "      <td>33.794868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>In the realm of infinite possibilities , where...</td>\n",
       "      <td>73</td>\n",
       "      <td>48.236008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  length  perplexity\n",
       "0    The sun sets , casting a golden glow across th...       7  123.059952\n",
       "1    Flowers bloom , adding vibrant colors to the g...       5  137.638031\n",
       "2    Laughter echoes through the air , filling hear...      10  125.766365\n",
       "3    Gentle raindrops fall , refreshing the earth w...       8  174.783737\n",
       "4    The moon shines brightly , illuminating the ni...       7   42.624065\n",
       "..                                                 ...     ...         ...\n",
       "139  High up in the mountains , where the air was c...      51   31.506687\n",
       "140  Under the starlit sky , a gentle breeze whispe...      61   47.097542\n",
       "141  In the realm of dreams , where imagination kno...      65   31.966364\n",
       "142  As the sun dipped below the horizon , painting...      70   33.794868\n",
       "143  In the realm of infinite possibilities , where...      73   48.236008\n",
       "\n",
       "[144 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed4e9050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_generation[df_generation['perplexity'] < 1000]['perplexity'].hist(bins = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54ba285b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "      <th>perplexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [text, length, perplexity]\n",
       "Index: []"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_generation[df_generation['perplexity'] > 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f84cb4b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>words</th>\n",
       "      <th>pos</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X can use any attack , PokÃ© - Power , or PokÃ© ...</td>\n",
       "      <td>19</td>\n",
       "      <td>NOUN AUX VERB DET NOUN PUNCT PROPN PUNCT PROPN...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>future</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>There were periods when everything was more op...</td>\n",
       "      <td>14</td>\n",
       "      <td>PRON VERB NOUN SCONJ PRON AUX ADV ADJ PUNCT CC...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>past</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trans people are terrified of what lies ahead .</td>\n",
       "      <td>9</td>\n",
       "      <td>PROPN NOUN AUX VERB ADP PRON VERB ADV PUNCT</td>\n",
       "      <td>negative</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Another Global horror is The Cube in Birmingha...</td>\n",
       "      <td>23</td>\n",
       "      <td>DET ADJ NOUN AUX DET PROPN ADP PROPN PUNCT DET...</td>\n",
       "      <td>negative</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The innovative one piece stainless steel shiel...</td>\n",
       "      <td>26</td>\n",
       "      <td>DET ADJ NUM NOUN ADJ NOUN VERB NOUN ADP PROPN ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11027</th>\n",
       "      <td>The application of Dye Solar Cells ( DSC 's ) ...</td>\n",
       "      <td>38</td>\n",
       "      <td>DET NOUN ADP PROPN PROPN PROPN PUNCT PROPN PAR...</td>\n",
       "      <td>positive</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11028</th>\n",
       "      <td>Along with the majority of Canadians elsewhere...</td>\n",
       "      <td>22</td>\n",
       "      <td>ADP ADP DET NOUN ADP PROPN ADV PUNCT PROPN VER...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>past</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11029</th>\n",
       "      <td>IBM , like other established tech companies , ...</td>\n",
       "      <td>33</td>\n",
       "      <td>PROPN PUNCT ADP ADJ VERB NOUN NOUN PUNCT VERB ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>past</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11030</th>\n",
       "      <td>Valuation movements ( think potential falls ) ...</td>\n",
       "      <td>23</td>\n",
       "      <td>NOUN NOUN PUNCT VERB ADJ NOUN PUNCT AUX NOUN V...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>future</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11031</th>\n",
       "      <td>Civil - liberties groups preferred the privacy...</td>\n",
       "      <td>23</td>\n",
       "      <td>ADJ PUNCT NOUN NOUN VERB DET NOUN NOUN ADP DET...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>past</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11032 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  words  \\\n",
       "0      X can use any attack , PokÃ© - Power , or PokÃ© ...     19   \n",
       "1      There were periods when everything was more op...     14   \n",
       "2        Trans people are terrified of what lies ahead .      9   \n",
       "3      Another Global horror is The Cube in Birmingha...     23   \n",
       "4      The innovative one piece stainless steel shiel...     26   \n",
       "...                                                  ...    ...   \n",
       "11027  The application of Dye Solar Cells ( DSC 's ) ...     38   \n",
       "11028  Along with the majority of Canadians elsewhere...     22   \n",
       "11029  IBM , like other established tech companies , ...     33   \n",
       "11030  Valuation movements ( think potential falls ) ...     23   \n",
       "11031  Civil - liberties groups preferred the privacy...     23   \n",
       "\n",
       "                                                     pos sentiment    tense  \n",
       "0      NOUN AUX VERB DET NOUN PUNCT PROPN PUNCT PROPN...   neutral   future  \n",
       "1      PRON VERB NOUN SCONJ PRON AUX ADV ADJ PUNCT CC...   neutral     past  \n",
       "2            PROPN NOUN AUX VERB ADP PRON VERB ADV PUNCT  negative  present  \n",
       "3      DET ADJ NOUN AUX DET PROPN ADP PROPN PUNCT DET...  negative  present  \n",
       "4      DET ADJ NUM NOUN ADJ NOUN VERB NOUN ADP PROPN ...  positive  present  \n",
       "...                                                  ...       ...      ...  \n",
       "11027  DET NOUN ADP PROPN PROPN PROPN PUNCT PROPN PAR...  positive  present  \n",
       "11028  ADP ADP DET NOUN ADP PROPN ADV PUNCT PROPN VER...   neutral     past  \n",
       "11029  PROPN PUNCT ADP ADJ VERB NOUN NOUN PUNCT VERB ...  positive     past  \n",
       "11030  NOUN NOUN PUNCT VERB ADJ NOUN PUNCT AUX NOUN V...   neutral   future  \n",
       "11031  ADJ PUNCT NOUN NOUN VERB DET NOUN NOUN ADP DET...   neutral     past  \n",
       "\n",
       "[11032 rows x 5 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mauve_compare = pd.read_csv('../230503_ucu_materials/data/val.csv')\n",
    "# df_mauve_compare['pos'] = df_mauve_compare.apply(lambda row: eval(row['pos']), axis=1)\n",
    "df_mauve_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6b00f8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mauve(human_df, generated_df):\n",
    "    if len(generated_df) > 5000: num_buckets = 500\n",
    "    else: num_buckets = 'auto'\n",
    "    return mauve.compute_mauve(p_text=human_df['text'].values.tolist(), q_text=generated_df['text'].values.tolist(), device_id=0, max_text_length=256, verbose=True, num_buckets=num_buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32edc10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer\n",
      "Tokenizing text...\n",
      "Loading tokenizer\n",
      "Loading model\n"
     ]
    }
   ],
   "source": [
    "compute_mauve(df_mauve_compare, df_generation).mauve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b320ab98",
   "metadata": {},
   "source": [
    "# 3. Distinctivness metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ffbd10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distinct_ngrams_in_sentence(df, n):\n",
    "    distinct_ngrams = []\n",
    "    for i in range(len(df)):\n",
    "        ngrams = list(nltk.ngrams(df['text'][i].split(), n))\n",
    "        unique_ngrams = set(ngrams)\n",
    "        if len(ngrams) > 0: distinct_ngrams.append(len(unique_ngrams)/len(ngrams))\n",
    "    return np.mean(distinct_ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7cb4312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8974394395231285"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_ngrams_in_sentence(df_generation, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae1745fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9975221790341818"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_ngrams_in_sentence(df_generation, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4536994c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_ngrams_in_sentence(df_generation, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc7cbdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distinct_ngrams_in_all_sentences(df, n):\n",
    "    ngrams = []\n",
    "    for i in range(len(df)):\n",
    "        ngrams += list(nltk.ngrams(df['text'][i].split(), n))\n",
    "    unique_ngrams = set(ngrams)\n",
    "    return len(unique_ngrams)/len(ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a90ba56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2853423587607394"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_ngrams_in_all_sentences(df_generation, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b9564e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6913713822017852"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_ngrams_in_all_sentences(df_generation, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c3637cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.880101322825781"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_ngrams_in_all_sentences(df_generation, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8c93f917",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distinct_endings(df, n):\n",
    "    sentence_endings = []\n",
    "    for i in range(len(df)):\n",
    "        sentence_endings.append(str(list(nltk.ngrams(df['text'][i].split(), 1))[-n:]))\n",
    "    unique_endings = set(sentence_endings)\n",
    "    return len(unique_endings)/len(sentence_endings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bbd6c2a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8125"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_endings(df_generation, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b7732b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9166666666666666"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_endings(df_generation, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1bf72cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distinct_beginnings(df, n):\n",
    "    sentence_beginnings = []\n",
    "    for i in range(len(df)):\n",
    "        sentence_beginnings.append(str(list(nltk.ngrams(df['text'][i].split(), 1))[:n]))\n",
    "    unique_beginnings = set(sentence_beginnings)\n",
    "    return len(unique_beginnings)/len(sentence_beginnings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "84677ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6805555555555556"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_beginnings(df_generation, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "94357084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8680555555555556"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_beginnings(df_generation, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "02e9880e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distinct_ngrams_for_repeated_pos(df, n):\n",
    "    ngrams_df = []\n",
    "    i = 0\n",
    "    while i < len(df):\n",
    "        ngrams = []\n",
    "        for j in range(5):\n",
    "            ngrams += list(nltk.ngrams(df['text'][i + j].split(), n))\n",
    "        unique_ngrams = set(ngrams)\n",
    "        i += 5\n",
    "        ngrams_df.append(len(unique_ngrams)/len(ngrams))\n",
    "    return np.mean(ngrams_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9a078b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9170178537943243"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_ngrams_for_repeated_pos(df_generation, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c78e7427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9735648592419011"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_ngrams_for_repeated_pos(df_generation, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "500b3e79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9939346350205104"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_ngrams_for_repeated_pos(df_generation, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9875ba12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distinct_endings_for_repeated_pos(df, n):\n",
    "    df_endings = []\n",
    "    i = 0\n",
    "    while i < len(df):\n",
    "        sentence_endings = []\n",
    "        for j in range(5):\n",
    "            sentence_endings.append(str(list(nltk.ngrams(df['text'][i + j].split(), 1))[-n:]))\n",
    "        unique_endings = set(sentence_endings)\n",
    "        i += 5\n",
    "        df_endings.append(len(unique_endings)/len(sentence_endings))\n",
    "    return np.mean(df_endings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1ba49983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_endings_for_repeated_pos(df_generation, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "046ab19f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9819999999999999"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_endings_for_repeated_pos(df_generation, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "35eaa626",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distinct_beginnings_for_repeated_pos(df, n):\n",
    "    df_beginnings = []\n",
    "    i = 0\n",
    "    while i < len(df):\n",
    "        sentence_beginnings = []\n",
    "        for j in range(5):\n",
    "            sentence_beginnings.append(str(list(nltk.ngrams(df['text'][i + j].split(), 1))[:n]))\n",
    "        unique_beginnings = set(sentence_beginnings)\n",
    "        i += 5\n",
    "        df_beginnings.append(len(unique_beginnings)/len(sentence_beginnings))\n",
    "    return np.mean(df_beginnings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "378b5e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_beginnings_for_repeated_pos(df_generation, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2fb63d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.961"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_beginnings_for_repeated_pos(df_generation, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f926610b",
   "metadata": {},
   "source": [
    "# 4. Repetition metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "670a51ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distinct_ngrams_repetition(df, df_train, n):\n",
    "    ngrams = []\n",
    "    for i in range(len(df)):\n",
    "        ngrams += list(nltk.ngrams(df['text'][i].split(), n))\n",
    "    ngrams_train = []\n",
    "    for i in range(len(df_train)):\n",
    "        ngrams_train += list(nltk.ngrams(df_train['text'][i].split(), n))\n",
    "    ngrams_rep = [x for x in ngrams if x in ngrams_train]\n",
    "    return 1-len(ngrams_rep)/len(ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "27002b76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5627926120286053"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_ngrams_repetition(df_generation, df_train, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "90a42bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.962665596146126"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_ngrams_repetition(df_generation, df_train, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
